<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">

        <!-- ===== CSS ===== -->
        <link rel="stylesheet" href="assets/css/styles.css">
        <link rel="stylesheet" href="assets/css/d3-mitch-tree.css">
        <link rel="stylesheet" href="assets/css/d3-mitch-tree-theme-default.css">
        <script src="assets/js/d3-mitch-tree.js"></script>

           <!-- Bootstrap CSS CDN -->
           <title>Characterizing Multimedia-rich OIE specific Tactics and Impact Assessment</title>
           <!-- Bootstrap CSS CDN -->
           <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.0/css/bootstrap.min.css" integrity="sha384-9gVQ4dYFwwWSjIDZnLEWnxCjeSWFphJiwGPXr1jddIhOegiu1FwO5qRGvFXOdJZ4" crossorigin="anonymous">
           <!-- Our Custom CSS -->
           <link rel="stylesheet" href="style.css">
       
           <!-- Font Awesome JS -->
           <script defer src="https://use.fontawesome.com/releases/v5.0.13/js/solid.js" integrity="sha384-tzzSw1/Vo+0N5UhStP3bvwWPq+uvzCMfrN1fEFe+xBmv1C/AtVX5K0uZtmcHitFZ" crossorigin="anonymous"></script>
           <script defer src="https://use.fontawesome.com/releases/v5.0.13/js/fontawesome.js" integrity="sha384-6OIrr52G08NpOFSZdxxz1xdNSndlD4vdcf/q2myIUVO0VsqaGHJsB0RaBE01VTOY" crossorigin="anonymous"></script>
       </head>

<body>
    <div class="wrapper">
        <!-- Sidebar  -->
        <nav id="sidebar">
            <div class="sidebar-header">
                <h3>Cosmos</h3>
            </div>

            <ul class="list-unstyled components">
                <li >
                    <a href="#overviewSubMenu" data-toggle="collapse" aria-expanded="false" class="dropdown-toggle">Overview</a>
                    <ul class="collapse list-unstyled" id="overviewSubMenu">
                        <li>
                            <a href="#reviewExistingSubMenu">Review of Existing Frameworks</a>
                            <a href="#">Missing Element: Multimedia Platforms</a>
                            <a href="#">Multimedia Characterization of Incidents</a>
                        </li>
                    </ul>

                    <!--Chacterization and tactics impact assesment -->
                    <a href="#characterizingTacticsImapactAssesment" data-toggle="collapse" aria-expanded="false" class="dropdown-toggle">Characterizing of Multimedia OIE</a>
                    <ul class="collapse list-unstyled" id="characterizingTacticsImapactAssesment">
                        <li>
                            <li>
                                <a href="./pages/characterizingTaticsAndImpactAssesment.html">Specific Tactics and Impact Assessment</a>
                                <a href="./pages/characterizingTaticsAndImpactAssesment.html">Commenter Flash Mob</a>
                                <a href="./pages/characterizingTaticsAndImpactAssesment.html">Coordinated Content Push</a>
                                <a href="./pages/characterizingTaticsAndImpactAssesment.html">Discourse Narrative Fusion</a>
                            </li>
                        </li>
                    </ul>

                    <!--Characterizing Dynamics of Social Campaign -->
                    <a href="./pages/characterizingDynamicsOfSocialCampaign.html">Characterizing Dynamics of Social Campaign</a>
                   
                    <!--Characterizing Information Actors and Consumers Dynamically -->
                    <a href="./pages/characterizingInformationActorsAndConsumersDynamically.html">Characterizing Information Actors & Consumers Dynamically</a>
    
                </li>
            </ul>

            <div class="solid-line"></div>

            <ul class="list-unstyled components">
               
            </ul>

            <!-- <ul class="list-unstyled CTAs">
                <li>
                    <a href="https://bootstrapious.com/tutorial/files/sidebar.zip" class="download">Download source</a>
                </li>
                <li>
                    <a href="https://bootstrapious.com/p/bootstrap-sidebar" class="article">Back to article</a>
                </li>
            </ul> -->
        </nav>

        <!-- Page Content  -->
        <div id="content">

            <nav class="navbar navbar-expand-lg ">
                <div class="container-fluid">
                    <h5>Multimedia Online Information Environment Characterization Framework</h5>
                    <button type="button" id="sidebarCollapse" class="btn btn-dark">
                        <i class="fas fa-align-justify"></i>
                    </button>
                </div>
            </nav>

            <div class="solid-line"></div>
            <div>
                <h5>Dynamic Multimedia Online Information Environment Characterization Framework</h5>
                <p>
                    In recent years, several frameworks have been proposed to communicate and characterize disinformation campaigns and incidents of information manipulation and interference online, while some have been incorporated into the existing institutional frameworks by government agencies and industry. Some of the proposed frameworks aimed at systematic documentation and communication of reported campaigns across institutions, while others focused on the characterization of behaviors, tactics, techniques, and procedures (TTPs) employed by threat actors. Also, a few frameworks characterize the narrative and rhetorical characteristics of influence in general. The existing frameworks offer great value in overall understanding and timely detection of influence operations. However, almost all the proposed frameworks cannot address the emerging developments in the modern information environment and pose a number of limitations to the characterization of high-risk hostile influence operations. In this study, we emphasize the use of multimedia environments, including video, audio, real-time broadcasting, and real-time audio chat environments for online influence operations as a high-priority area of focus for an additional computational and analytical framework. All in all, we posit that the expansion of the current set of frameworks with a multi-modal approach toward such social media platforms would improve the efforts to monitor, track, detect, and mitigate the emerging threats in the information environment.
                </p>

            </div>

            <!--01 Review of Existing Framework-->
            <div class="solid-line"></div>
            <div>
                <h5>Review of Existing Frameworks</h5>
                <p>
                    This section provides a quick summary of the existing frameworks to characterize and communicate disinformation, and incidents of influence operations across online platforms. Although this section includes some of the most prominent and widely mentioned frameworks, it is non-exhaustive, as efforts by governments, intergovernmental organizations, and the industry to adapt to the evolving threat environment continue.               
                 </p>
            </div>
            <div class="solid-line"></div>
            <div class="collapsible" id="framework-for-actor">
                <button type="button" class="collapsible_button">
                    <h5>Frameworks for Actor Motivation, Documentation, and Inter-Institutional Communication
                    </h5>
                </button>
                      
                <div class="collapsible-content">
                    <div>
                        <p>
                            Prominently after Russian Federation's illegal annexation of Crimea (2014), and its interference in democratic processes in Western countries (2016 onwards), as well as the proliferation of hostile influence campaigns across the world, a great number of studies (policy and academic) focused on the analysis, detection, and characterization of disinformation online, with a wide-ranging topical diversity ranging from the detection of computational propaganda to the use of automated accounts, narratives, coordinated information maneuvers, platform architectures, root causes, susceptibility of audiences, and to strategic/tactical characterization of hostile actors. Overall, the mental models and conceptual frameworks varied across thousands of studies.                  
                        </p>
                        <p>
                            In recent years, some frameworks have been proposed (and partially adopted) to improve the characterization of influence operations across agencies for more effective documentation, understanding, and mitigation of threat incidents. The ABCDE Framework is among the most recent frameworks that achieved significant adoption across different government entities, especially in the European Union. The framework is based on five primary analytical components for the characterization of detected influence operations: Actor, Behavior, Content, Degree, and Effect. According to the original report, each component in the ABCDE framework can be formalized as a set of questions (see figure 1).
                        </p>
                        <div>
                            <img src="assets/images/abcdediagram.png" alt=”abcde-diagram” style="width: 200px;height:auto;">
                        </div>
                        <p>
                            More recently, the SCOTCH framework has been proposed in an Atlantic Council publication as a result of a series of expert consultations across institutions. The SCOTCH Framework aims to enable inter-institutional and structured communication of the findings regarding the detected/assessed incidents of hostile influence operations and disinformation across online platforms. Namely, the components of the framework are the Source, Channel, Objective, Target, Composition, and Hook. Overall, the elements of the SCOTCH Framework can be mapped to the structure of the ABCDE Framework, as the two frameworks have some similarities in their original objectives. However, the SCOTCH framework has a greater emphasis on the platform architectures, actor motivations (original intent), strategic objectives, and targets of the influence operations. Moreover, the SCOTCH Framework also emphasizes the "Bottom Line Up Front" assessments, similar to the long-lasting intelligence analysis best practices, mainly for quick and effective communication.
                        </p>
                        <p>
                            Before the ABCDE and SCOTCH frameworks, several other proposals existed. For example, in a joint proposal by Graphika and Harvard University, "Disinformation ABC" aimed at characterizing online disinformation across three vectors: "A" for manipulative actors, "B" for deceptive behavior, and "C" for harmful content. Later, a different proposal added the "D" vector to the ABC, to address the need for understanding "information distribution" dynamics in influence operations. The Information Disorder framework, as a broader conceptual framework for understanding the information incidents and campaigns, included both object types and phases of any information event. For object types, the information disorder framework includes the Agent, Message, and Interpreter elements, while each campaign/incident is characterized by considering the "Creation", "Reproduction", and "Distribution" phases.
                        </p>
                        <p>
                            Also, other frameworks had application-specific focus. For example, "the Department of Justice (DoJ) Framework to Counter Malign Foreign Influence Operations" intuitively had a legal perspective on hostile influence. Conceptually, the DoJ framework also introduced a combined articulation of cybersecurity threats and malign influence campaigns. The major categories in the DoJ framework are "cyber operations targeting election infrastructure, cyber operations targeting political parties, campaigns, and public officials, covert influence operations to assist or harm political organizations, campaigns and public officials, covert influence operations to influence public opinion and sow division, and overt influence efforts to influence policymakers and the public". 
                        </p>
                    </div>
                </div>
            </div>
            <div class="collapsible" id="framework-for-process">
                <button type="button" class="collapsible_button">
                    <h5>Frameworks Focusing on Process, TTPs, Behaviors
                    </h5>
                </button>
                      
                <div class="collapsible-content">
                    <p>
                        The second major category of analytical frameworks focuses on the processes that often include multiple phases, and associated behaviors, tactics, techniques, and procedures (TTPs). More often than not, frameworks in this category rely on two types of conceptualizations. In the first group, the influence campaigns are assessed within a framework similar to pre-existing best practices of cybersecurity, resembling the "cyber kill chains". The second group of frameworks relies on the categorization of narrative-related, rhetorical, social, and network-centric maneuvers in the information domain.
                    </p>
                    <p>
                        The concept of "social media kill chains" was proposed as a structured process to assess hostile influence, based on the previously existed workflows of the cyber kill chain. The social media kill chain concept includes staging, reconnaissance, targeting, mimicry, content placement, amplification, and mobilization. In the given conceptual framework, each phase has a different set of relevant analytical questions and potential tactical components. In a relevant framework articulated in a report by the Department of Homeland Security (DHS), "Disinformation Kill Chain" included Recon, Build, Seed, Copy, Amplify, Control, and Effect phases (see figure 2). The DHS framework mapped phases of the disinformation kill chain with corresponding response themes, drivers, and potential mitigation efforts. 
                    </p>
                    <div>
                        <img src="../assets/images/disinformationkilldiagram.png" alt=disinformationkilldiagram style="width: 200px;height:auto;">
                    </div>
                    <p>
                        Within the same family of cybersecurity inspired frameworks, the DISARM Framework, which originally started with the name of AMITT (Adversarial Misinformation and Influence Tactics and Techniques), maps the influence operation TTPs across different phases and strategic components. The DISARM/AMITT was built on the MITRE ATT&CK framework for cybersecurity. The four phases of hostile influence campaigns in the DISARM include the planning, preparation, execution, and evaluation, while the overall operational categories range from strategic planning to objective planning, people developing, network developing, microtargeting, content developing, channel selection, pump-priming, exposure, physical aspects, persistence, and effectiveness measuring. Each operational component of the DISARM has a number of documented influence operation techniques than can be used to characterize an ongoing or previous incident/campaign (see figure 3).
                    </p>
                    <p>
                        Another recent framework, RICHDATA, has been proposed by a research group at the Center for Security and Emerging Technology. The RICHDATA framework mostly resembles the DISARM/AMITT, with phases including Reconnaissance, Infrastructure, Content Creation & Hijacking, Deployment, Amplification, Troll Patrol, and Actualization.  
                    </p>
                    <p>
                        As mentioned above, the second type of frameworks in this category emphasizes the narrative-related, behavioral, and network-centric "maneuvers" exhibited in online influence operations. In one of the earliest and most widely adopted examples, the "4Ds of disinformation" behaviors were outlined as "dismiss", "distort", "distract", and "dismay", often adopted as a conceptual framework to characterize the Russian disinformation campaigns. Other more recent frameworks built on the "4Ds" model, adding new behavioral and narrative-related components to the characterization of influence operations. The BEND Framework, for example, maps the relevant behaviors across 16 different behaviors, categorized as information and network maneuvers.  

                    </p>
                    <p>
                        Accordingly, the BEND behaviors include maneuvers that manipulate information/narratives, or social/communication networks.
                    </p>
                    <div>
                        <img src="../assets/images/disarm-diagram.png" alt=disarm-diagram” style="width: 200px;height:auto;">
                    </div>
                    <p>
                        Finally, as an example of narrative-related, and rhetorical frameworks of influence in general, the "Playmaker Taxonomy of Influence Strategies" maps the rhetorical and social maneuvers of influence. While the taxonomy was used to analyze the Russian Federation's influence strategies in a recent report by the NATO Strategic Communications Centre of Excellence, the given framework is not specific to hostile influence campaigns online.
                    </p>
                </div>
            </div>

            <!-- 02 Missing Elements: Multimedia Platforms and Multimodal Characterization -->
            <div class="solid-line"></div>
            <div id="sectionHeader">
                <h5>The Missing Element: Multimedia Platforms and Multimodal Characterization</h5>
                <p>
                    Each analytical and conceptual framework mentioned above offers value to the assessment of online influence operations. However, the relevant literature and policy-relevant toolkit still lack a framework that would, in combination with some of the existing frameworks, address the emerging characteristics of multimedia platforms and cross-platform dynamics in the contemporary information environment. Most of the existing analytical workflows rely on text-based analysis of threat actors and information manipulation incidents, with limited, time-consuming, and mostly qualitative assessments of the artifacts, content, or actors present in multimedia environments. In addition, most of the current knowledge regarding the online influence operations relies on the given analytical workflows and text-based computational tools, which in turn pose significant limitations to the overarching understanding of how current hostile operations are conducted, or which artifacts they use. Furthermore, existing frameworks focus on platforms that are primarily user-centric (e.g., Twitter, Facebook, WhatsApp). Emerging multimedia based platforms (e.g., YouTube, TikTok, Parler, Clubhouse) are primarily content-centric. TTPs of influence operations are shaped by the platform architectures, and what is available as manipulative tools. By mostly relying on the text-based tools that are mostly applied to data originating from a certain list of social media platforms such as Twitter, the overwhelming majority of the current frameworks often fall short of offering a comprehensive view of how multiple modalities of signals from video, audio, text, network, user/content-engagement, and platform affordances are combined.
                </p>
                <p>
                    Therefore, we propose building an additional framework, with an emphasis on multimedia environments, to complement the existing frameworks of hostile influence operations.
                </p>
            </div>     

            <!--03 Multimodal Characterization of Incidents in Multimedia Online Information Environment-->

            <div class="solid-line"></div>
            <div>
                <h5>Multimodal Characterization of Incidents in Multimedia Online Information Environment</h5>
                <p>
                    The following section outlines the data and content types, and analytical approaches we have focused on in our research in recent years. Our goal is to combine the given components in an overarching conceptual framework to support the current efforts to characterize relevant incidents and campaigns in the information environment.                </p>
            </div>

            <div class="collapsible" id="video-signal">
                <button type="button" class="collapsible_button">
                    <h5>Video Signals
                    </h5>
                </button>
                        
                <div class="collapsible-content">
                    <p>Video barcode extraction and color theory-based assessment enable the detection and characterization of inauthentic, manipulative, or suspicious content amplification behaviors. Video barcode analysis enables the extraction of similar and almost identical video objects through a scalable and very fast embedding of each video in a low-dimensional space that may include a very high number of videos. This characterization can also be elevated to group-level by focusing on channels, content producers, topical content groups, or other groups that exhibit network structures. In addition to the content amplification aspect, the deeper analysis of video barcodes and underlying color signals may enable the identification of intent, motivation, as well as the systematic use of emotional and cognitive cues in the content promoted by threat actors. Such signals do not necessarily exist and are identifiable in text-based approaches other existing methods are built on.</p>
                    <p>Other computational frameworks for video-based characterization include detection or classification of objects, detection of scenes, or detection of movements. Although this line of research is currently developing and the existing products achieve varying performance with significant computational requirements, it is a valuable addition to the workflows that aim at characterizing the video objects that become the artifacts of hostile influence operations. Using object, face, movement, and scene detection techniques, we can identify the repetitive and systematic content production tactics. In addition, analysts can retrieve sets of computationally embedded entities (objects, persons, graphical/visual items) from resulting databases that include previously identified incidents, campaigns, or content.</p>
                </div>
            </div>

            <div class="collapsible" id="audio-signal">
                <button type="button" class="collapsible_button">
                    <h5>Audio Signals
                    </h5>
                </button>
                        
                <div class="collapsible-content">
                    <p>
                        In addition to images and videos, sophisticated influence operations utilize audio for increasing the impact on human behaviors, beliefs, and cognition. For example, audio signals often include emotional triggers (such as anger, disgust, or fear) that increase the penetration capabilities of amplified messages or narratives. The existing text-based analytical frameworks can't capture such operational and increasingly significant traces. Video-based platforms such as YouTube and TikTok, and audio-based artifacts such as podcasts and live community-level audio-chats (Clubhouse, Twitter’s Spaces, etc.), have been becoming the core pillars of online information dissemination, often facilitating the rapid spread of messages that are untraceable through text-based computational workflows. Although the frameworks such as BEND maneuvers include psycholinguistic features embedded in the text, they often rely on bag-of-words techniques to analyze text. Both audio and video data are represented in higher dimensions than text. Emotional cues are often hidden in the audio signals such as peaks and emphasis on words (intonations) or even lower-level segments of speech. Therefore, our current line of work includes the characterization of audio signals.
                    </p>
                </div>
            </div>

            <div class="collapsible" id="audio-signal">
                <button type="button" class="collapsible_button">
                    <h5>Text Signals
                    </h5>
                </button>
                        
                <div class="collapsible-content">
                    <p>
                        In combination with video-based and audio-based signals, textual features enrich the analysis and characterization of influence operations in multimedia environments. Adding to the existing analytical frameworks that characterize narrative and content-specific attributes, the multi-modal approach adopted by our techniques aims at the characterization of features associated with the "content producers" (actor) and "content consumers" (target audience). For example, textual data such as video transcripts, channel descriptions, video titles, and video descriptions signal behavioral characteristics of content producers on YouTube, especially when jointly embedded with video, audio, network, and engagement-specific features. Secondly, textual attributes extracted from comments, commenters, reply to comments, and conversational threads signal the basic characteristics of target audiences as well as their reactions to the incoming streams of targeted information. Therefore, by combining the text-based features with other components of the multi-modal computational framework, we also aim at capturing the impact or degree of influence operations that are being assessed.  
                     </p>
                </div>
            </div>

            <div class="collapsible" id="audio-signal">
                <button type="button" class="collapsible_button">
                    <h5>Network Signals
                    </h5>
                </button>
                        
                <div class="collapsible-content">
                    <p>
                        More often than not, the existing frameworks of disinformation and social cybersecurity incidents include network-centric approaches to uncover tactical, technical, behavioral, and procedural traces of influence operations on online platforms. As demonstrated in the previous reports, networks of commenter cliques and mobs provide strong signals of inauthentic behaviors across YouTube channels. While many commenter mobs from one video to another of the same channel, some mobs are shown to span across different channels to effect discourse fusion – a tactic known to manipulate recommendation algorithm (more on this is covered in section on “Platform Affordances”). In addition, platforms such as YouTube also include channel subscriber or shared-commenter networks, which further show the latent connections between content producer and disseminator entities.                 
                    </p>
                    
                    <p>
                        In recent years, the popularity of graph machine learning algorithms has increased across a wide variety of application domains. Relevant to this work, both earlier graph representation techniques and newer graph deep neural networks are proposed for fraud detection, threat hunting (cybersecurity), fake news propagation detection, and coordination detection tasks. As an example of the use cases of more traditional and older methods, a recent study combined "shallow" graph embedding techniques (node2vec) with text embedding to classify malicious news sharing networks of coordinated accounts. However, modern graph learning algorithms enable even better results. The primary strength of graph learning algorithms comes from their ability to capture structural information, hierarchical relationships, and features related to information flows in networks. Graph representation learning and graph neural networks constitute a branch of machine learning research, with several similarities to modern image recognition systems and transformer-based language models such as widely adopted BERT, GPT-3, and others
                    </p>
                    <p>
                        Graph learning approaches can be applied to any network-related data, hence enabling many non-trivial solutions to problems about online information flows, social networks, and popular social media platforms. In particular, when combined with other state-of-the-art deep learning systems of NLP, computer vision, and even traditional machine learning, graph neural networks may enable significant improvements to the abovementioned problem areas. On the other hand, networks (graphs) consist of irregular and asymmetric structures and they are with dynamic complexities. Therefore the graph learning approaches require special handling due to their differences from modern deep learning applications such as image recognition. For example, in recent years, multiple methods have been proposed by diverse research groups to "detect fake news" (some of these tasks look more like the detection of behaviors). The proposed solutions tackle different problems such as predicting the fake content, detecting bots, detecting rumor sources, and detecting fake news/disinformation propagation networks. More often than not, the promising solutions combine multiple machine learning tasks.
                        <br>In the context of this project, graph representation learning would enable the "mapping" and 2D/3D representation of detected information incidents (each incident as a graph, each graph as an entity in the final space), especially in comparison with instances of similar incidents over time, and with information incidents led by other actors. For example, we may be able to represent the similarities and differences of incidents (distance), in terms of the information captured by the respective coordination networks, and their structural properties. When needed, the networks can be supported by additional layers of information with applications of computer vision (use of similar images) or natural language processing (textual content).
                    </p>
                </div>
            </div>

            <div class="collapsible" id="audio-signal">
                <button type="button" class="collapsible_button">
                    <h5>Engagement Signals
                    </h5>
                </button>
                        
                <div class="collapsible-content">
                    <p>
                        Despite a limited view of user engagements on amplified pieces of information, most of the current frameworks do not capture the meaningful analysis of engagements within the context of influence operations. Social media listening tools and relevant computational workflows often include engagement metrics as a proxy for the overall reach of any content. However, multimedia platforms such as YouTube, TikTok, and some audio-based platforms are often vulnerable to coordinated manipulation of user engagements. Across the world, many commercial black-market and PR entities offer such manipulation as part of their "disinformation as a service" packages. Also, threat actors that have significant experience, personnel, organizational structure, financial power, and computational infrastructure employ such capabilities in the manipulation of user engagements for further amplification of their messages. Often, multimedia platforms either lack the capabilities to eliminate the manipulation of engagement metrics, or their countermeasures lag behind the attackers, introducing significant time gaps between the initial manipulation and the correction of engagement metrics. Such metrics include the number of views, number of likes, number of comments (with embedded likes, dislikes, and replies), and number of subscribers.         
                    </p>
                </div>
            </div>

            <div class="collapsible" id="metadata-signal">
                <button type="button" class="collapsible_button">
                    <h5>Metadata Signals
                    </h5>
                </button>
                        
                <div class="collapsible-content">
                    <p>
                        Metadata signals enable additional views of influence operations on multimedia environments. For example, data types such as cross-platform URL link networks, location metadata, timestamps (channel, account, producer, video, podcast, comment), and content categories are incorporated in the analysis. Most of the proposed approaches remain focused on a single platform and stop the analytical workflow exactly when the information starts achieving broader impact across multiple or even many social media platforms. Broadening the focus on multimedia platforms and multi-modal computational assessments enable us to detect and characterize additional significant operational traces and discover influence pathways.                   
                     </p>
                </div>
            </div>

            <div class="collapsible" id="platform-signal">
                <button type="button" class="collapsible_button">
                    <h5>Platform Affordances
                    </h5>
                </button>
                        
                <div class="collapsible-content">
                    <p>
                        Multimedia based social platforms being content-centric platforms, afford unique manipulative tools for adversarial information operations. Recommender systems, for instance, have a significant influence on the dissemination and consumption of the content, especially on multimedia platforms. In 2018, YouTube's Chief product officer mentioned that 70% of watch time on YouTube is spent watching videos the algorithm recommends. As already depicted in many studies (including ours), recommender systems exhibit unintended bias and unfair behaviors that lead to the promotion of harmful content or the formation of filter bubbles. Moreover, inauthentic and artificial commenter behaviors, manipulation of user engagements, shilling attacks, exploitation of data voids, and more sophisticated adversarial attacks aim at the alteration of recommender behavior that would promote the content amplified by threat actors. Further, such an approach does not remain limited to actor-networks but also uncovers content networks. Given the architectures of modern social media platforms, once crossing the tipping points of overall reach, content moves and spreads rapidly across many networks. Finally, the current literature suggests that the hyperactive users and content producers achieve higher amplification by platform recommendations. Therefore, the multi-modal assessments of influence campaigns in a framework that includes such multimedia environments should incorporate and combine the network-centric views of content producers, content consumers, and platform recommender systems.
                    </p>
                </div>
            </div>

            <!--04 Taxonomy of Data and Analytics for Multimedia rich OIE -->
            <div class="solid-line"></div>

            <div>
                <h5>Dynamic Characterization of Information Producers </h5>
                <p>
                    We leverage the diffusion of innovations (DOI) theory to show how users adopt into social 
                    media campaigns. The psychological and social behaviors that are understood from the DOI 
                    model can be applied to social networks to categorize social media users into adoption categories
                    and to use diffusion curves to determine if a campaign has reached its tipping point (see Figure 
                    2). We demonstrate this application of DOI theory to social networks in (Spann, et al., 2022), 
                    where we show how the spread of misinformation follows a trajectory pattern similar to the 
                    adoption of new technologies. The framework in this proposal considers these two approaches to
                    understanding the diffusion of information in a connective action campaign. This view can be 
                    used to help shape collective identity and understand whether a collective response is a function 
                    of aggregation effects or specific interaction conditions within a group. This research also 
                    consider how online social networks are used for the purpose of social media campaigns. The 
                    sociotechnical theories of affordance and interdependence amongst users are applied to    
                    understand how individual user participation impacts the rate of adoption into an information 
                    campaign. The interactions between users in a connective action campaign can provide insights 
                    to help determine how future actors will react as information propagates through the network. 
                    Leonardi distinguished between these types of actions by labeling them as individualized, shared,
                    and collective affordances (Leonardi, 2013). The interdependencies created between users 
                    creates a production function that allows us to measure the diffusion of information in a cyber 
                    campaign. The initial observations from our analysis support a mathematical characterization for 
                    connective action campaigns and show how affordances can be used to identify the inter-user 
                    message strategy (Spann, et al., 2020).
                    Figure 2. Diffusion of Innovation (DOI) model and stages for user adoption (left). Model of s-
                    curve campaign cycle trajectory (right).
                    We leverage the diffusion of innovations (DOI) theory to examine the trajectory of the overall 
                    campaign as it evolves. The second derivative test is then applied to identify changes in the slope
                    of the s-curve. The second derivative test is a method in multivariable calculus used to determine
                    if a critical point of a function is a local minimum, maximum or saddle point. This empirical 
                    approach provides an initial quantitative method to find the points at which the slope of the 
                    curves shifts from the accelerating stage to the point at which the campaign reaches maximum 
                    diffusion or critical mass, and when the slope flattens out or enters the decelerating stage. Since 
                    DOI theory has been applied to various disciplines, a key benefit to this approach is that the s-
                    curves are platform independent. Understanding these processes provides a foundation for 
                 </p>
            </div>

            <div class="solid-line"></div>
            <div id="high-level-diagram">
                <button type="button" class="collapsible_button">
                    <h5>High Level Diagram
                    </h5>
                </button>
                        
                <div id="my_tree" style="width: 80%;height: 800px;"></div>
            </div>


        </div>
    </div>        

    <!-- jQuery CDN - Slim version (=without AJAX) -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <!-- Popper.JS -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.0/umd/popper.min.js" integrity="sha384-cs/chFZiN24E4KMATLdqdvsezGxaGsi4hLGOzlXwp5UZB1LY//20VyM2taTB4QvJ" crossorigin="anonymous"></script>
    <!-- Bootstrap JS -->
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.0/js/bootstrap.min.js" integrity="sha384-uefMccjFJAIv6A+rW+L4AHf99KvxDjWSu1z9VI8SKNVmz4sk7buKt/6v9KI65qnm" crossorigin="anonymous"></script>

    <script type="text/javascript">
        $(document).ready(function () {
            $('#sidebarCollapse').on('click', function () {
                $('#sidebar').toggleClass('active');
            });
        });
        $(function () {
            $('.panel-collapse').on('show.bs.collapse', function () {
                $(this).siblings('.panel-heading').addClass('active');
            });
 
            $('.panel-collapse').on('hide.bs.collapse', function () {
                $(this).siblings('.panel-heading').removeClass('active');
            });
        });
    </script>
        <!-- ===== MAIN JS ===== -->
        <script src="assets/js/main.js"></script>
</body>

</html>